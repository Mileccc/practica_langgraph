{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph,END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')\n",
    "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ChatGroq(temperature=0, model=\"llama3-70b-8192\", streaming=False)\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, streaming=True)\n",
    "model = ChatAnthropic(model=\"claude-3-haiku-20240307\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Hola! ¿Cómo estás?', response_metadata={'id': 'msg_01JQjUQ5MQFbkzHpd6daNb5g', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 9, 'output_tokens': 20}}, id='run-7fd387d0-839d-4036-b4b4-a7a46bbd5713-0')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke('hola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(first_number: int, second_number: int):\n",
    "    \"\"\"Multiplica dos números.\"\"\"\n",
    "    return first_number * second_number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_with_tools = model.bind(tools=[convert_to_openai_tool(multiply)])\n",
    "# response = model_with_tools.invoke('Cuanto es 35 * 46?')\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'text': 'Vamos a calcular 35 * 46 utilizando la herramienta \"multiply\":', 'type': 'text'}, {'id': 'toolu_01SoxQtkkSFFdTLuHM7oDFnG', 'input': {'first_number': 35, 'second_number': 46}, 'name': 'multiply', 'type': 'tool_use'}], response_metadata={'id': 'msg_012TtBmacBrqpP4npuWC6RuT', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 374, 'output_tokens': 96}}, id='run-67fe3aae-5f93-411b-a463-95c0f9519d16-0', tool_calls=[{'name': 'multiply', 'args': {'first_number': 35, 'second_number': 46}, 'id': 'toolu_01SoxQtkkSFFdTLuHM7oDFnG'}])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [multiply]\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "response = model_with_tools.invoke('Cuanto es 35 * 46?')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = [multiply]\n",
    "# model_with_tools = model.bind_tools(tools)\n",
    "# response = model_with_tools.invoke('Que es un LLM?')\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'first_number': 35, 'second_number': 46},\n",
       "  'id': 'toolu_01SoxQtkkSFFdTLuHM7oDFnG'}]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls = response.tool_calls\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'first_number': 35, 'second_number': 46},\n",
       "  'id': 'toolu_01SoxQtkkSFFdTLuHM7oDFnG'}]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_calls = response.additional_kwargs.get('tool_calls')\n",
    "# tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Name: multiply\n",
      "Function Arguments: {'first_number': 35, 'second_number': 46}\n",
      "{'name': 'multiply', 'args': {'first_number': 35, 'second_number': 46}, 'id': 'toolu_01SoxQtkkSFFdTLuHM7oDFnG'}\n"
     ]
    }
   ],
   "source": [
    "for tool_call in tool_calls:\n",
    "    print('Function Name:',tool_call.get('name'))\n",
    "    print('Function Arguments:',tool_call.get('args'))\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del Gráfico con llamada condicional a aristas y herramientas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model(state):\n",
    "    messages = state['messages']\n",
    "    question = messages[-1]## Fetching the user question\n",
    "    return {\"messages\":[model_with_tools.invoke(question)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_tool(state):\n",
    "    print(\"******************DERIvADO***************\")\n",
    "    tool_calls = state['messages'][-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    multiply_call = None\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call.get(\"function\").get(\"name\") == \"multiply\":\n",
    "            multiply_call = tool_call\n",
    "\n",
    "    if multiply_call is None:\n",
    "        raise Exception(\"No se ha encontrado ninguna entrada para sumar.\")\n",
    "\n",
    "    res = multiply.invoke(\n",
    "        json.loads(multiply_call.get(\"function\").get(\"arguments\"))\n",
    "        # Convierte una cadena JSON a un diccionario de Python '{\"first_number\": 35, \"second_number\": 46}'\n",
    "    )\n",
    "\n",
    "    return {\"messages\" : [res]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state):\n",
    "    tool_calls = state['messages'][-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    if len(tool_calls):\n",
    "        return \"multiply\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", invoke_model)\n",
    "graph.add_node(\"tool\", invoke_tool)\n",
    "graph.add_edge(\"tool\", END)\n",
    "graph.add_conditional_edges(\"agent\", router, {\n",
    "    \"multiply\": \"tool\",\n",
    "    \"end\": END,\n",
    "})\n",
    "graph.set_entry_point(\"agent\")\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = app.invoke({\"messages\": [\"Cuanto es 123 * 456?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': ['Cuanto es 123 * 456?',\n",
       "  AIMessage(content=[{'id': 'toolu_01Vw1dKDnnL5zHy8N28UaXc5', 'input': {'first_number': 123, 'second_number': 456}, 'name': 'multiply', 'type': 'tool_use'}], response_metadata={'id': 'msg_01NK1SxPLJmVtQKou9DqmD3i', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 374, 'output_tokens': 72}}, id='run-475bf1e4-bcb8-48d0-8e46-b7452b820845-0', tool_calls=[{'name': 'multiply', 'args': {'first_number': 123, 'second_number': 456}, 'id': 'toolu_01Vw1dKDnnL5zHy8N28UaXc5'}])]}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'id': 'toolu_01Vw1dKDnnL5zHy8N28UaXc5', 'input': {'first_number': 123, 'second_number': 456}, 'name': 'multiply', 'type': 'tool_use'}], response_metadata={'id': 'msg_01NK1SxPLJmVtQKou9DqmD3i', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 374, 'output_tokens': 72}}, id='run-475bf1e4-bcb8-48d0-8e46-b7452b820845-0', tool_calls=[{'name': 'multiply', 'args': {'first_number': 123, 'second_number': 456}, 'id': 'toolu_01Vw1dKDnnL5zHy8N28UaXc5'}])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = app.invoke({\"messages\": [\"Que es LLM?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': ['Que es LLM?',\n",
       "  AIMessage(content='LLM significa \"Large Language Model\" (Modelo de Lenguaje a Gran Escala). Se trata de un tipo de modelo de aprendizaje automático basado en redes neuronales profundas que ha sido entrenado en grandes cantidades de datos de texto para aprender a comprender y generar lenguaje natural.\\n\\nAlgunas características clave de los LLM:\\n\\n- Están entrenados en enormes cantidades de datos de texto de Internet, libros, artículos, etc. Lo que les permite aprender sobre una gran variedad de temas y dominios.\\n\\n- Pueden comprender y generar texto de manera muy natural, parecido a como lo haría un ser humano.\\n\\n- Tienen la capacidad de realizar una amplia gama de tareas relacionadas con el lenguaje, como responder preguntas, hacer resúmenes, traducir entre idiomas, generar texto creativo, etc.\\n\\n- Utilizan arquitecturas como Transformers que les permiten aprender representaciones semánticas profundas del lenguaje.\\n\\n- Ejemplos prominentes de LLM incluyen GPT-3, BERT, T5, entre otros desarrollados por empresas como OpenAI, Google, Microsoft, etc.\\n\\nLos LLM han tenido un gran impacto en el campo del procesamiento de lenguaje natural y se están utilizando cada vez más en aplicaciones reales como asistentes virtuales, generación de contenido, sistemas de diálogo, etc.', response_metadata={'id': 'msg_01EWFcEaQqzUEWLiYNhm3HdB', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 370, 'output_tokens': 349}}, id='run-6be37ef2-0a4b-4e83-a8b2-ab1212ddccbe-0')]}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LLM significa \"Large Language Model\" (Modelo de Lenguaje a Gran Escala). Se trata de un tipo de modelo de aprendizaje automático basado en redes neuronales profundas que ha sido entrenado en grandes cantidades de datos de texto para aprender a comprender y generar lenguaje natural.\\n\\nAlgunas características clave de los LLM:\\n\\n- Están entrenados en enormes cantidades de datos de texto de Internet, libros, artículos, etc. Lo que les permite aprender sobre una gran variedad de temas y dominios.\\n\\n- Pueden comprender y generar texto de manera muy natural, parecido a como lo haría un ser humano.\\n\\n- Tienen la capacidad de realizar una amplia gama de tareas relacionadas con el lenguaje, como responder preguntas, hacer resúmenes, traducir entre idiomas, generar texto creativo, etc.\\n\\n- Utilizan arquitecturas como Transformers que les permiten aprender representaciones semánticas profundas del lenguaje.\\n\\n- Ejemplos prominentes de LLM incluyen GPT-3, BERT, T5, entre otros desarrollados por empresas como OpenAI, Google, Microsoft, etc.\\n\\nLos LLM han tenido un gran impacto en el campo del procesamiento de lenguaje natural y se están utilizando cada vez más en aplicaciones reales como asistentes virtuales, generación de contenido, sistemas de diálogo, etc.' response_metadata={'id': 'msg_01EWFcEaQqzUEWLiYNhm3HdB', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 370, 'output_tokens': 349}} id='run-6be37ef2-0a4b-4e83-a8b2-ab1212ddccbe-0'\n"
     ]
    }
   ],
   "source": [
    "print(output['messages'][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2email",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
